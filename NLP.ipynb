{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61dcd79a",
   "metadata": {},
   "source": [
    "# NLP analysis objectives\n",
    "- switch to outscraper to extract full information of reviews ✓\n",
    "- check if the place might have water army?\n",
    "- extract the most related\n",
    "- use sentiment analysis to analysis the score rather than using google score\n",
    "- NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7165a63",
   "metadata": {},
   "source": [
    "# To Do:\n",
    "- download a set of data with only reviews and rating or Aurther ✓\n",
    "- Word2vec to show its true reviews\n",
    "- sentiment analysis to measure its true value\n",
    "## data preprocessing:\n",
    "- stopword ✓\n",
    "- lemmetize ✓\n",
    "- porterstemmer (clean liked like liking into like) ✓\n",
    "- embedding ✓\n",
    "- train test split ✓\n",
    "- word2vec after cleaning ✓\n",
    "- onehotencoding y as well\n",
    "\n",
    "# Tech issue\n",
    "- maybe code a function to download necessary nlp trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57efda02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error EOF occurred in\n",
      "[nltk_data]     violation of protocol (_ssl.c:1131)>\n",
      "[nltk_data] Error loading punkt: <urlopen error EOF occurred in\n",
      "[nltk_data]     violation of protocol (_ssl.c:1131)>\n",
      "[nltk_data] Error loading wordnet: <urlopen error EOF occurred in\n",
      "[nltk_data]     violation of protocol (_ssl.c:1131)>\n",
      "[nltk_data] Error loading omw-1.4: <urlopen error EOF occurred in\n",
      "[nltk_data]     violation of protocol (_ssl.c:1131)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import re,string\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca6daff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  My wife took me here on my birthday for breakf...      5\n",
       "1  I have no idea why some people give bad review...      5\n",
       "2  love the gyro plate. Rice is so good and I als...      4\n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...      5\n",
       "4  General Manager Scott Petello is a good egg!!!...      5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data_references/yelp.csv')\n",
    "df=df[['text','stars']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "837d9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(word):\n",
    "    model= stopwords.words('english')\n",
    "    trim_s=WordNetLemmatizer()\n",
    "    stem=PorterStemmer()\n",
    "    word = ''.join([i for i in str(word) if not i.isdigit()])\n",
    "    word = word_tokenize(word.lower())\n",
    "    word = [i for i in set(word) if i.isalpha() and i not in string.punctuation and i not in model]\n",
    "    word = [trim_s.lemmatize(i) for i in word]\n",
    "    word = [stem.stem(i) for i in word]\n",
    "    \n",
    "    return \" \".join(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fdf4134",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['true_review']=np.vectorize(clean_data)(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e9fdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>true_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>5</td>\n",
       "      <td>sit piec absolut menu anyway better amaz arriv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>5</td>\n",
       "      <td>forev seat person show small host past thought...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>4</td>\n",
       "      <td>gyro rice plate good candi select love dig also</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>5</td>\n",
       "      <td>field trash job basebal love clean desert can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>5</td>\n",
       "      <td>mistak life surpris respect alway state thank ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars  \\\n",
       "0  My wife took me here on my birthday for breakf...      5   \n",
       "1  I have no idea why some people give bad review...      5   \n",
       "2  love the gyro plate. Rice is so good and I als...      4   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...      5   \n",
       "4  General Manager Scott Petello is a good egg!!!...      5   \n",
       "\n",
       "                                         true_review  \n",
       "0  sit piec absolut menu anyway better amaz arriv...  \n",
       "1  forev seat person show small host past thought...  \n",
       "2    gyro rice plate good candi select love dig also  \n",
       "3  field trash job basebal love clean desert can ...  \n",
       "4  mistak life surpris respect alway state thank ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2c8cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['true_review']\n",
    "y=df[['stars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf75d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y=[]\n",
    "for i in df.stars:\n",
    "    if i ==5:\n",
    "        new_y.append([0,0,0,0,1])\n",
    "    elif i ==4:\n",
    "        new_y.append([0,0,0,1,0])\n",
    "    elif i ==3:\n",
    "        new_y.append([0,0,1,0,0])\n",
    "    elif i ==2:\n",
    "        new_y.append([0,1,0,0,0])\n",
    "    else:\n",
    "        new_y.append([1,0,0,0,0])\n",
    "new_y=np.array(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfd4f44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, new_y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edf98aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(sentences=X_train, vector_size=60, min_count=1, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b29e084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-11 16:14:11.341696: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-11 16:14:11.341732: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "def embed_sentence(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "\n",
    "# Embed the training and test sentences\n",
    "X_train_embed = embedding(word2vec, X_train)\n",
    "X_test_embed = embedding(word2vec, X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_embed, dtype='float32', padding='post', maxlen=50)\n",
    "X_test_pad = pad_sequences(X_test_embed, dtype='float32', padding='post', maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cef01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking())\n",
    "    model.add(layers.LSTM(20, activation='tanh'))\n",
    "    model.add(layers.Dense(15, activation='relu'))\n",
    "    model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "model=init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf4fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train_pad, y_train, \n",
    "          batch_size = 64,\n",
    "          epochs=500,\n",
    "          callbacks=[es],\n",
    "          validation_data=(X_test_pad,y_test)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f266a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!git add NLP.ipynb\n",
    "!git commit -m 'try 500 epoch'\n",
    "!git push origin master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f6f4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
