{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61dcd79a",
   "metadata": {},
   "source": [
    "# NLP analysis objectives\n",
    "- switch to outscraper to extract full information of reviews ✓\n",
    "- check if the place might have water army?\n",
    "- extract the most related\n",
    "- use sentiment analysis to analysis the score rather than using google score\n",
    "- NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7165a63",
   "metadata": {},
   "source": [
    "# To Do:\n",
    "- download a set of data with only reviews and rating or Aurther ✓\n",
    "- Word2vec to show its true reviews\n",
    "- sentiment analysis to measure its true value\n",
    "## data preprocessing:\n",
    "- stopword ✓\n",
    "- lemmetize ✓\n",
    "- porterstemmer (clean liked like liking into like) ✓\n",
    "- embedding ✓\n",
    "- train test split ✓\n",
    "- word2vec after cleaning ✓\n",
    "- onehotencoding y as well\n",
    "\n",
    "# Tech issue\n",
    "- maybe code a function to download necessary nlp trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57efda02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n",
      "[nltk_data]     Temporary failure in name resolution>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno -3] Temporary\n",
      "[nltk_data]     failure in name resolution>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [Errno -3] Temporary\n",
      "[nltk_data]     failure in name resolution>\n",
      "[nltk_data] Error loading omw-1.4: <urlopen error [Errno -3] Temporary\n",
      "[nltk_data]     failure in name resolution>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import re,string\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca6daff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  My wife took me here on my birthday for breakf...      5\n",
       "1  I have no idea why some people give bad review...      5\n",
       "2  love the gyro plate. Rice is so good and I als...      4\n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...      5\n",
       "4  General Manager Scott Petello is a good egg!!!...      5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data_references/yelp.csv')\n",
    "df=df[['text','stars']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "837d9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(word):\n",
    "    model= stopwords.words('english')\n",
    "    trim_s=WordNetLemmatizer()\n",
    "    stem=PorterStemmer()\n",
    "    word = ''.join([i for i in str(word) if not i.isdigit()])\n",
    "    word = word_tokenize(word.lower())\n",
    "    word = [i for i in set(word) if i.isalpha() and i not in string.punctuation and i not in model]\n",
    "    word = [trim_s.lemmatize(i) for i in word]\n",
    "    word = [stem.stem(i) for i in word]\n",
    "    \n",
    "    return \" \".join(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fdf4134",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['true_review']=np.vectorize(clean_data)(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e9fdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>true_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>5</td>\n",
       "      <td>white fresh outsid egg best blend truffl absol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>5</td>\n",
       "      <td>decid price tri show give like calzon forev ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>4</td>\n",
       "      <td>good gyro select also candi plate dig rice love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>5</td>\n",
       "      <td>path surround sniff lot field let ballpark dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>5</td>\n",
       "      <td>manag total thank satisfi staff like go issu c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars  \\\n",
       "0  My wife took me here on my birthday for breakf...      5   \n",
       "1  I have no idea why some people give bad review...      5   \n",
       "2  love the gyro plate. Rice is so good and I als...      4   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...      5   \n",
       "4  General Manager Scott Petello is a good egg!!!...      5   \n",
       "\n",
       "                                         true_review  \n",
       "0  white fresh outsid egg best blend truffl absol...  \n",
       "1  decid price tri show give like calzon forev ba...  \n",
       "2    good gyro select also candi plate dig rice love  \n",
       "3  path surround sniff lot field let ballpark dep...  \n",
       "4  manag total thank satisfi staff like go issu c...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2c8cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['true_review']\n",
    "y=df[['stars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf75d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y=[]\n",
    "for i in df.stars:\n",
    "    if i ==5:\n",
    "        new_y.append([0,0,0,0,1])\n",
    "    elif i ==4:\n",
    "        new_y.append([0,0,0,1,0])\n",
    "    elif i ==3:\n",
    "        new_y.append([0,0,1,0,0])\n",
    "    elif i ==2:\n",
    "        new_y.append([0,1,0,0,0])\n",
    "    else:\n",
    "        new_y.append([1,0,0,0,0])\n",
    "new_y=np.array(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfd4f44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, new_y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edf98aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(sentences=X_train, vector_size=60, min_count=1, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b29e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "def embed_sentence(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "\n",
    "# Embed the training and test sentences\n",
    "X_train_embed = embedding(word2vec, X_train)\n",
    "X_test_embed = embedding(word2vec, X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_embed, dtype='float32', padding='post', maxlen=200)\n",
    "X_test_pad = pad_sequences(X_test_embed, dtype='float32', padding='post', maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63cef01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking())\n",
    "    model.add(layers.LSTM(20, activation='tanh'))\n",
    "    model.add(layers.Dense(15, activation='relu'))\n",
    "    model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "model=init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bf4fc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "105/105 [==============================] - 20s 148ms/step - loss: 1.4689 - accuracy: 0.3442 - val_loss: 1.4208 - val_accuracy: 0.3561\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 14s 132ms/step - loss: 1.4272 - accuracy: 0.3631 - val_loss: 1.4121 - val_accuracy: 0.3606\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 1.4211 - accuracy: 0.3634 - val_loss: 1.4085 - val_accuracy: 0.3858\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 14s 132ms/step - loss: 1.4177 - accuracy: 0.3685 - val_loss: 1.4064 - val_accuracy: 0.3800\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 16s 155ms/step - loss: 1.4118 - accuracy: 0.3745 - val_loss: 1.4046 - val_accuracy: 0.3882\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 18s 174ms/step - loss: 1.4100 - accuracy: 0.3787 - val_loss: 1.4079 - val_accuracy: 0.3779\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 19s 178ms/step - loss: 1.4033 - accuracy: 0.3843 - val_loss: 1.4049 - val_accuracy: 0.3891\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 19s 178ms/step - loss: 1.4043 - accuracy: 0.3809 - val_loss: 1.4094 - val_accuracy: 0.3852\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 19s 184ms/step - loss: 1.3992 - accuracy: 0.3896 - val_loss: 1.4077 - val_accuracy: 0.3842\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 19s 182ms/step - loss: 1.3976 - accuracy: 0.3875 - val_loss: 1.3999 - val_accuracy: 0.3858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe23c43e670>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train_pad, y_train, \n",
    "          batch_size = 64,\n",
    "          epochs=10,\n",
    "          callbacks=[es],\n",
    "          validation_data=(X_test_pad,y_test)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f266a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!git add NLP.ipynb\n",
    "!git commit -m 'need to improve the accuracy of the model'\n",
    "!git push origin master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0961ca96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
